"""
FMixæ•°æ®å¢å¼ºå¯è§†åŒ–è„šæœ¬
=============================
FMixæ˜¯ä¸€ç§åŸºäºå‚…é‡Œå¶ç©ºé—´ä½é¢‘æ©ç çš„æ··åˆæ•°æ®å¢å¼ºæ–¹æ³•ã€‚
å®ƒé€šè¿‡åœ¨é¢‘åŸŸç”Ÿæˆä½é¢‘æ©ç ï¼Œå°†ä¸¤å¼ å›¾åƒè¿›è¡Œæ··åˆï¼Œç”Ÿæˆå…·æœ‰è‡ªç„¶è¿‡æ¸¡è¾¹ç•Œçš„å¢å¼ºæ ·æœ¬ã€‚

å‚è€ƒæ–‡çŒ®:
    Harris E, Marcu A, Sherrill M, et al.
    FMix: Enhancing mixed sample data augmentation[J].
    arXiv preprint arXiv:2002.12047, 2020.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
import torch.nn.functional as F
from torchvision import transforms
from model_utils import BrainTumorFinalNet

# ================= é…ç½®åŒºåŸŸ =================
# ç±»åˆ«åç§°
CLASS_NAMES = ['glioma', 'meningioma', 'no_tumor', 'pituitary']

# æ¨¡å‹è·¯å¾„ (ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹)
MODEL_PATH = './checkpoints_ablation/PureBase_CLAHE_FMix_CA/PureBase_CLAHE_FMix_CA_best_model.pth'
MODEL_CONFIG = {
    'num_classes': 4,
    'use_dcn': False,
    'use_ca': True,
    'use_symmetry': False
}

# è¾“å‡ºç›®å½•
OUTPUT_DIR = './fmix_visualization'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ç¤ºä¾‹å›¾ç‰‡
SAMPLE_IMAGES = [
    ('data/val/glioma/100820_10_751.jpg', 'glioma'),
    ('data/val/meningioma/101801_1_471.jpg', 'meningioma'),
    ('data/val/no_tumor/IXI024_Axial_52_no_tumor.jpg', 'no_tumor'),
    ('data/val/pituitary/103478_10_1500.jpg', 'pituitary'),
]
# ============================================


# ================= æ¨¡å‹åŠ è½½å‡½æ•° =================
def load_model(model_path, model_config, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    model = BrainTumorFinalNet(**model_config).to(device)
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    
    if isinstance(checkpoint, dict):
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
    else:
        return checkpoint.to(device).eval()
    
    # æ¸…æ´—state_dict
    clean_state_dict = {}
    for k, v in state_dict.items():
        if "total_ops" not in k and "total_params" not in k:
            new_key = k.replace("module.", "")
            clean_state_dict[new_key] = v
    
    model.load_state_dict(clean_state_dict, strict=False)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    return model


def predict_image(model, img_np, device):
    """å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹"""
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    img_pil = Image.fromarray(img_np.astype(np.uint8))
    img_tensor = transform(img_pil).unsqueeze(0).to(device)
    
    with torch.no_grad():
        output = model(img_tensor)
        probs = F.softmax(output, dim=1)
        conf, pred_idx = torch.max(probs, 1)
    
    return CLASS_NAMES[pred_idx.item()], conf.item(), probs[0].cpu().numpy()


# ================= FMixæ ¸å¿ƒå‡½æ•° (ä¸train_album.pyå®Œå…¨ç›¸åŒ) =================
def fftfreqnd(h, w=None, z=None):
    """ç”Ÿæˆé¢‘ç‡ç½‘æ ¼ - åŸå§‹è®­ç»ƒè„šæœ¬ç‰ˆæœ¬"""
    fz = fx = 0
    fy = np.fft.fftfreq(h)
    if w is not None: 
        fx = np.fft.fftfreq(w)
    if z is not None: 
        fz = np.fft.fftfreq(z)
    return np.meshgrid(fy, fx, indexing='ij')


def get_spectrum(freq_space, decay_power=2):
    """ç”Ÿæˆé¢‘åŸŸè°± - åŸå§‹è®­ç»ƒè„šæœ¬ç‰ˆæœ¬"""
    scale = np.ones(1) / (np.maximum(freq_space, np.array([1. / max(freq_space.shape)])) ** decay_power)
    param_size = [len(freq_space)] + list(freq_space.shape)
    param = np.random.randn(*param_size)
    return np.expand_dims(scale, axis=0) * param


def make_low_freq_image(decay, shape, ch=1):
    """ç”Ÿæˆä½é¢‘æ©ç  - åŸå§‹è®­ç»ƒè„šæœ¬ç‰ˆæœ¬"""
    freq_space = fftfreqnd(shape[0], shape[1])
    spectrum = get_spectrum(np.array(freq_space), decay_power=decay)
    mask = np.real(np.fft.ifft2(spectrum[:1])).astype(np.float32)
    mask = mask[0, 0] if mask.ndim == 4 else mask[0]
    if mask.ndim > 2: 
        mask = mask[0]
    mask = mask - mask.min()
    return mask / mask.max()


def fmix_images(img1, img2, alpha=1.0, decay_power=3.0):
    """
    å¯¹ä¸¤å¼ å›¾åƒæ‰§è¡ŒFMixæ··åˆ
    
    å‚æ•°:
        img1: ç¬¬ä¸€å¼ å›¾åƒ (H, W, C), numpy array, å€¼èŒƒå›´[0, 255]
        img2: ç¬¬äºŒå¼ å›¾åƒ (H, W, C), numpy array, å€¼èŒƒå›´[0, 255]
        alpha: Betaåˆ†å¸ƒå‚æ•°ï¼Œæ§åˆ¶æ··åˆæ¯”ä¾‹Î»
        decay_power: é¢‘ç‡è¡°å‡ç³»æ•°
    
    è¿”å›:
        mixed_img: æ··åˆåçš„å›¾åƒ
        soft_mask: åŸå§‹è¿ç»­æ©ç 
        binary_mask: äºŒå€¼åŒ–åçš„æ©ç 
        lam: æ··åˆæ¯”ä¾‹
    """
    assert img1.shape == img2.shape, "ä¸¤å¼ å›¾åƒå°ºå¯¸å¿…é¡»ç›¸åŒ"
    h, w = img1.shape[:2]
    
    # 1. ä»Betaåˆ†å¸ƒé‡‡æ ·æ··åˆæ¯”ä¾‹Î»
    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1
    
    # 2. ç”Ÿæˆä½é¢‘è½¯æ©ç 
    soft_mask = make_low_freq_image(decay_power, (h, w))
    
    # 3. æ ¹æ®Î»å°†è½¯æ©ç äºŒå€¼åŒ–
    mask_flat = soft_mask.flatten()
    idx = int((1 - lam) * len(mask_flat))
    threshold = np.partition(mask_flat, idx)[idx]
    binary_mask = (soft_mask > threshold).astype(np.float32)
    
    # 4. ä½¿ç”¨äºŒå€¼æ©ç æ··åˆå›¾åƒ
    binary_mask_3d = binary_mask[:, :, np.newaxis]
    mixed_img = img1 * binary_mask_3d + img2 * (1 - binary_mask_3d)
    mixed_img = mixed_img.astype(np.uint8)
    
    # è®¡ç®—å®é™…æ··åˆæ¯”ä¾‹
    actual_lam = binary_mask.mean()
    
    return mixed_img, soft_mask, binary_mask, actual_lam


def visualize_fmix_process(img1, img2, label1, label2, output_path, 
                           decay_power=3.0, alpha=1.0, model=None, device=None):
    """
    å¯è§†åŒ–FMixçš„å®Œæ•´å¤„ç†è¿‡ç¨‹
    å±•ç¤ºï¼šåŸå›¾1ã€åŸå›¾2ã€è½¯æ©ç ã€äºŒå€¼æ©ç ã€æ··åˆç»“æœã€æ¨¡å‹é¢„æµ‹
    """
    # æ‰§è¡ŒFMix
    mixed_img, soft_mask, binary_mask, lam = fmix_images(
        img1, img2, alpha=alpha, decay_power=decay_power
    )
    
    # æ¨¡å‹é¢„æµ‹
    pred_info = ""
    if model is not None and device is not None:
        pred1, conf1, _ = predict_image(model, img1, device)
        pred2, conf2, _ = predict_image(model, img2, device)
        pred_mix, conf_mix, probs_mix = predict_image(model, mixed_img, device)
        pred_info = f"\nModel Predictions: Aâ†’{pred1}({conf1:.2f}), Bâ†’{pred2}({conf2:.2f}), Mixâ†’{pred_mix}({conf_mix:.2f})"
    
    # åˆ›å»ºå›¾å½¢
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    fig.suptitle(f'FMix Data Augmentation Visualization\n'
                 f'(Harris et al., 2020) | decay_power={decay_power}, Î»={lam:.3f}{pred_info}', 
                 fontsize=13, fontweight='bold')
    
    # ç¬¬ä¸€è¡Œ
    axes[0, 0].imshow(img1)
    title_a = f'Image A\n({label1})'
    if model is not None:
        color_a = 'green' if pred1 == label1 else 'red'
        title_a += f'\nPred: {pred1} ({conf1:.2f})'
        axes[0, 0].set_title(title_a, fontsize=12, color=color_a)
    else:
        axes[0, 0].set_title(title_a, fontsize=12)
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(img2)
    title_b = f'Image B\n({label2})'
    if model is not None:
        color_b = 'green' if pred2 == label2 else 'red'
        title_b += f'\nPred: {pred2} ({conf2:.2f})'
        axes[0, 1].set_title(title_b, fontsize=12, color=color_b)
    else:
        axes[0, 1].set_title(title_b, fontsize=12)
    axes[0, 1].axis('off')
    
    axes[0, 2].imshow(mixed_img)
    title_mix = f'FMix Result\nAÃ—{lam:.2f} + BÃ—{1-lam:.2f}'
    if model is not None:
        title_mix += f'\nPred: {pred_mix} ({conf_mix:.2f})'
    axes[0, 2].set_title(title_mix, fontsize=12)
    axes[0, 2].axis('off')
    
    # ç¬¬äºŒè¡Œ
    im_soft = axes[1, 0].imshow(soft_mask, cmap='viridis')
    axes[1, 0].set_title('Soft Mask (Low-Freq Image)\nGenerated via FFT', fontsize=12)
    axes[1, 0].axis('off')
    plt.colorbar(im_soft, ax=axes[1, 0], fraction=0.046, pad=0.04)
    
    axes[1, 1].imshow(binary_mask, cmap='gray')
    axes[1, 1].set_title(f'Binary Mask\nThreshold by Î»={lam:.3f}', fontsize=12)
    axes[1, 1].axis('off')
    
    # æ˜¾ç¤ºæ©ç å åŠ åœ¨æ··åˆå›¾ä¸Š
    overlay = mixed_img.copy().astype(np.float32)
    # ç”¨çº¢è‰²è¾¹ç•Œæ ‡å‡ºæ©ç è¾¹ç¼˜
    from scipy import ndimage
    edges = ndimage.sobel(binary_mask)
    edges = (np.abs(edges) > 0.1).astype(np.float32)
    overlay[:, :, 0] = np.clip(overlay[:, :, 0] + edges * 200, 0, 255)
    axes[1, 2].imshow(overlay.astype(np.uint8))
    axes[1, 2].set_title('Mixed Image with\nMask Boundary (Red)', fontsize=12)
    axes[1, 2].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")
    return lam


def visualize_decay_power_comparison(img1, img2, label1, label2, output_path):
    """
    å±•ç¤ºä¸åŒdecay_powerå‚æ•°å¯¹æ©ç çš„å½±å“
    decay_powerè¶Šå¤§ï¼Œç”Ÿæˆçš„æ©ç è¶Šå¹³æ»‘ï¼ˆä½é¢‘æˆåˆ†è¶Šå¤šï¼‰
    """
    decay_powers = [1.0, 2.0, 3.0, 5.0]
    
    fig, axes = plt.subplots(len(decay_powers), 4, figsize=(16, 4*len(decay_powers)))
    fig.suptitle('FMix: Effect of Decay Power on Mask Smoothness\n'
                 'Higher decay_power â†’ Smoother boundaries (more low-frequency)', 
                 fontsize=14, fontweight='bold', y=1.02)
    
    np.random.seed(42)  # å›ºå®šéšæœºç§å­ä»¥ä¾¿å¯¹æ¯”
    
    for i, dp in enumerate(decay_powers):
        np.random.seed(42)  # æ¯æ¬¡é‡ç½®ï¼Œä¿è¯åªæœ‰decay_powerä¸åŒ
        mixed_img, soft_mask, binary_mask, lam = fmix_images(
            img1, img2, alpha=1.0, decay_power=dp
        )
        
        axes[i, 0].imshow(soft_mask, cmap='viridis')
        axes[i, 0].set_title(f'Soft Mask\ndecay_power={dp}', fontsize=11)
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(binary_mask, cmap='gray')
        axes[i, 1].set_title(f'Binary Mask\nÎ»={lam:.3f}', fontsize=11)
        axes[i, 1].axis('off')
        
        axes[i, 2].imshow(mixed_img)
        axes[i, 2].set_title(f'FMix Result', fontsize=11)
        axes[i, 2].axis('off')
        
        # FFTé¢‘è°±å¯è§†åŒ–
        spectrum = np.abs(np.fft.fftshift(np.fft.fft2(soft_mask)))
        spectrum_log = np.log1p(spectrum)
        axes[i, 3].imshow(spectrum_log, cmap='hot')
        axes[i, 3].set_title(f'Frequency Spectrum\n(log scale)', fontsize=11)
        axes[i, 3].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")


def visualize_multiple_samples(images_data, output_path, model=None, device=None):
    """
    å±•ç¤ºå¤šç»„FMixæ ·æœ¬ï¼ˆå¸¦æ¨¡å‹é¢„æµ‹ï¼‰
    """
    n = len(images_data) // 2
    if n < 2:
        n = 2
    
    fig, axes = plt.subplots(n, 5, figsize=(20, 4*n))
    fig.suptitle('FMix Augmentation Examples on Brain Tumor MRI\n'
                 '(Harris et al., 2020)', 
                 fontsize=14, fontweight='bold', y=1.02)
    
    for i in range(n):
        # é€‰æ‹©ä¸¤å¼ ä¸åŒçš„å›¾ç‰‡è¿›è¡Œæ··åˆ
        idx1 = i % len(images_data)
        idx2 = (i + 1) % len(images_data)
        
        img1_path, label1 = images_data[idx1]
        img2_path, label2 = images_data[idx2]
        
        if not os.path.exists(img1_path) or not os.path.exists(img2_path):
            continue
        
        img1 = np.array(Image.open(img1_path).convert('RGB').resize((224, 224)))
        img2 = np.array(Image.open(img2_path).convert('RGB').resize((224, 224)))
        
        mixed_img, soft_mask, binary_mask, lam = fmix_images(
            img1, img2, alpha=1.0, decay_power=3.0
        )
        
        # æ¨¡å‹é¢„æµ‹
        pred_mix_str = ""
        if model is not None and device is not None:
            pred_mix, conf_mix, _ = predict_image(model, mixed_img, device)
            pred_mix_str = f"\nPred: {pred_mix} ({conf_mix:.2f})"
        
        axes[i, 0].imshow(img1)
        axes[i, 0].set_title(f'Image A\n({label1})', fontsize=11)
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(img2)
        axes[i, 1].set_title(f'Image B\n({label2})', fontsize=11)
        axes[i, 1].axis('off')
        
        axes[i, 2].imshow(binary_mask, cmap='gray')
        axes[i, 2].set_title(f'Binary Mask\nÎ»={lam:.3f}', fontsize=11)
        axes[i, 2].axis('off')
        
        axes[i, 3].imshow(mixed_img)
        axes[i, 3].set_title(f'FMix Result{pred_mix_str}', fontsize=11)
        axes[i, 3].axis('off')
        
        # æ ‡ç­¾ä¿¡æ¯
        axes[i, 4].text(0.5, 0.5, 
                        f"Mix Info:\n\n"
                        f"Label A: {label1}\n"
                        f"Label B: {label2}\n\n"
                        f"Î» = {lam:.3f}\n\n"
                        f"Loss:\n"
                        f"Î»Ã—L(A) + (1-Î»)Ã—L(B)",
                        ha='center', va='center', fontsize=12,
                        transform=axes[i, 4].transAxes,
                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        axes[i, 4].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")


def visualize_fmix_vs_cutmix(img1, img2, label1, label2, output_path):
    """
    å¯¹æ¯”FMixå’ŒCutMixçš„åŒºåˆ«
    """
    h, w = img1.shape[:2]
    lam = 0.5
    
    # FMix
    mixed_fmix, soft_mask, binary_mask_fmix, actual_lam = fmix_images(
        img1, img2, alpha=1.0, decay_power=3.0
    )
    
    # CutMix (ç®€å•çŸ©å½¢è£å‰ª)
    cut_ratio = np.sqrt(1 - lam)
    cut_w = int(w * cut_ratio)
    cut_h = int(h * cut_ratio)
    cx = np.random.randint(w)
    cy = np.random.randint(h)
    x1 = np.clip(cx - cut_w // 2, 0, w)
    x2 = np.clip(cx + cut_w // 2, 0, w)
    y1 = np.clip(cy - cut_h // 2, 0, h)
    y2 = np.clip(cy + cut_h // 2, 0, h)
    
    binary_mask_cutmix = np.ones((h, w), dtype=np.float32)
    binary_mask_cutmix[y1:y2, x1:x2] = 0
    
    mixed_cutmix = img1.copy()
    mixed_cutmix[y1:y2, x1:x2] = img2[y1:y2, x1:x2]
    
    # ç»˜å›¾
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    fig.suptitle('FMix vs CutMix Comparison\n'
                 'FMix uses low-frequency masks for natural boundaries', 
                 fontsize=14, fontweight='bold')
    
    # åŸå›¾
    axes[0, 0].imshow(img1)
    axes[0, 0].set_title(f'Image A ({label1})', fontsize=11)
    axes[0, 0].axis('off')
    
    axes[0, 1].imshow(img2)
    axes[0, 1].set_title(f'Image B ({label2})', fontsize=11)
    axes[0, 1].axis('off')
    
    # CutMix
    axes[0, 2].imshow(binary_mask_cutmix, cmap='gray')
    axes[0, 2].set_title('CutMix Mask\n(Rectangular)', fontsize=11)
    axes[0, 2].axis('off')
    
    axes[0, 3].imshow(mixed_cutmix)
    axes[0, 3].set_title('CutMix Result\n(Sharp edges)', fontsize=11)
    axes[0, 3].axis('off')
    
    # FMix
    axes[1, 0].imshow(soft_mask, cmap='viridis')
    axes[1, 0].set_title('FMix Soft Mask\n(Low-frequency)', fontsize=11)
    axes[1, 0].axis('off')
    
    axes[1, 1].imshow(binary_mask_fmix, cmap='gray')
    axes[1, 1].set_title(f'FMix Binary Mask\nÎ»={actual_lam:.3f}', fontsize=11)
    axes[1, 1].axis('off')
    
    axes[1, 2].imshow(mixed_fmix)
    axes[1, 2].set_title('FMix Result\n(Natural boundaries)', fontsize=11)
    axes[1, 2].axis('off')
    
    # å¯¹æ¯”è¯´æ˜
    axes[1, 3].text(0.5, 0.5, 
                    "Key Differences:\n\n"
                    "CutMix:\n"
                    "â€¢ Rectangular masks\n"
                    "â€¢ Sharp, unnatural edges\n"
                    "â€¢ Simple spatial mixing\n\n"
                    "FMix:\n"
                    "â€¢ Fourier-based masks\n"
                    "â€¢ Smooth, organic shapes\n"
                    "â€¢ More realistic augmentation",
                    ha='center', va='center', fontsize=11,
                    transform=axes[1, 3].transAxes,
                    bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
    axes[1, 3].axis('off')
    
    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ¨ FMixæ•°æ®å¢å¼ºå¯è§†åŒ–")
    print("   åŸºäº Harris et al., arXiv 2020")
    print("="*60)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    model = None
    if os.path.exists(MODEL_PATH):
        model = load_model(MODEL_PATH, MODEL_CONFIG, device)
    else:
        print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}ï¼Œå°†ä¸æ˜¾ç¤ºé¢„æµ‹ç»“æœ")
    
    # åŠ è½½ç¤ºä¾‹å›¾ç‰‡
    valid_images = []
    for img_path, label in SAMPLE_IMAGES:
        if os.path.exists(img_path):
            valid_images.append((img_path, label))
        else:
            print(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
    
    if len(valid_images) < 2:
        # è‡ªåŠ¨ä»éªŒè¯é›†é€‰æ‹©
        print("\nğŸ” è‡ªåŠ¨ä»éªŒè¯é›†é€‰æ‹©å›¾ç‰‡...")
        val_dir = './data/val'
        for cls_name in CLASS_NAMES:
            cls_dir = os.path.join(val_dir, cls_name)
            if os.path.exists(cls_dir):
                files = [f for f in os.listdir(cls_dir) 
                        if f.endswith(('.jpg', '.tif', '.png'))]
                if files:
                    valid_images.append((os.path.join(cls_dir, files[0]), cls_name))
    
    if len(valid_images) < 2:
        print("âŒ éœ€è¦è‡³å°‘2å¼ å›¾ç‰‡æ¥æ¼”ç¤ºFMix!")
        return
    
    print(f"\nâœ… æ‰¾åˆ° {len(valid_images)} å¼ å›¾ç‰‡")
    
    # åŠ è½½ä¸¤å¼ ç¤ºä¾‹å›¾ç‰‡
    img1_path, label1 = valid_images[0]
    img2_path, label2 = valid_images[1]
    
    img1 = np.array(Image.open(img1_path).convert('RGB').resize((224, 224)))
    img2 = np.array(Image.open(img2_path).convert('RGB').resize((224, 224)))
    
    print(f"\nğŸ“· å›¾ç‰‡A: {label1}")
    print(f"ğŸ“· å›¾ç‰‡B: {label2}")
    
    # 1. FMixå®Œæ•´è¿‡ç¨‹å¯è§†åŒ– (å¸¦æ¨¡å‹é¢„æµ‹)
    print("\n[1/4] ç”ŸæˆFMixå¤„ç†è¿‡ç¨‹å¯è§†åŒ–...")
    visualize_fmix_process(
        img1, img2, label1, label2,
        os.path.join(OUTPUT_DIR, 'fmix_process.png'),
        decay_power=3.0,
        model=model, device=device
    )
    
    # 2. decay_powerå‚æ•°å¯¹æ¯”
    print("[2/4] ç”Ÿæˆdecay_powerå‚æ•°å¯¹æ¯”...")
    visualize_decay_power_comparison(
        img1, img2, label1, label2,
        os.path.join(OUTPUT_DIR, 'fmix_decay_power_comparison.png')
    )
    
    # 3. å¤šç»„æ ·æœ¬å±•ç¤º
    print("[3/4] ç”Ÿæˆå¤šç»„FMixæ ·æœ¬...")
    visualize_multiple_samples(
        valid_images,
        os.path.join(OUTPUT_DIR, 'fmix_multiple_samples.png'),
        model=model, device=device
    )
    
    # 4. FMix vs CutMixå¯¹æ¯”
    print("[4/4] ç”ŸæˆFMix vs CutMixå¯¹æ¯”...")
    visualize_fmix_vs_cutmix(
        img1, img2, label1, label2,
        os.path.join(OUTPUT_DIR, 'fmix_vs_cutmix.png')
    )
    
    print("\n" + "="*60)
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
    print("âœ… å®Œæˆ!")


if __name__ == '__main__':
    main()
